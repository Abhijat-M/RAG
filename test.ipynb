{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c217210",
   "metadata": {},
   "source": [
    "# RAG 2.0 — Feature Test Notebook\n",
    "\n",
    "\n",
    "This notebook is a structured, fully-documented test suite for the RAG application. Each section contains contextual markdown, code cells with purpose comments, expected outputs, and simple validation notes.\n",
    "\n",
    "⚠️ **Run this notebook from the `RAG/` project directory. Ensure `.env` and dependencies are present.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8560b4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup & Environment\n",
    "\n",
    "**Purpose:** Verify environment, .env, and dependencies. Expected: env vars loaded and paths resolved.\n",
    "\n",
    "**How to validate:** See the expected outputs in the code cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: Load modules and configuration, verify .env variables.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Prints env vars summary and version info.\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cccbefc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Ingestion\n",
    "\n",
    "**Purpose:** Upload or crawl documents and URLs. Expected: text extraction confirmations.\n",
    "\n",
    "**How to validate:** See the expected outputs in the code cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: Test document ingestion for sample files or URLs.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Extracted text snippet(s) printed and saved.\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from config import Config, IS_CONFIG_VALID\n",
    "from core.knowledge_graph import KnowledgeGraphBuilder\n",
    "from core.rag_engine import RAGEngine\n",
    "from ingestion.document_processor import DocumentProcessor\n",
    "from ingestion.web_crawler import WebCrawler\n",
    "from logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: Test document ingestion for sample files or URLs.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Extracted text snippet(s) printed and saved.\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def pjson(obj):\n",
    "    \"\"\"Pretty-print JSON to stdout.\"\"\"\n",
    "    print(json.dumps(obj, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c7689f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Text Processing & Chunking\n",
    "\n",
    "**Purpose:** Normalize text and split into semantic chunks. Expected: chunk counts and stats.\n",
    "\n",
    "**How to validate:** See the expected outputs in the code cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9019c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: Text cleaning and chunking routines.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Number of chunks and a sample chunk shown.\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "if not IS_CONFIG_VALID:\n",
    "    logger.error(\"CRITICAL: .env file is not configured correctly. Please check it.\")\n",
    "    raise RuntimeError(\"Invalid configuration\")\n",
    "\n",
    "logger.info(\"Configuration is valid.\")\n",
    "print(f\"LLM Provider : {Config.LLM_PROVIDER}\")\n",
    "print(f\"LLM Model    : {Config.LLM_MODEL}\")\n",
    "print(f\"Vector Store : {Config.VECTOR_STORE_TYPE}\")\n",
    "\n",
    "rag = RAGEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55094ccd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Embedding Generation\n",
    "\n",
    "**Purpose:** Generate vector embeddings for chunks using configured embedding model. Expected: embeddings shape and latency metrics.\n",
    "\n",
    "**How to validate:** See the expected outputs in the code cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: Embedding model initialization and batching.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Embeddings shape (n_chunks, dim) printed.\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "logger.warning(\"Clearing vector store for a clean test…\")\n",
    "rag.clear_vector_store()\n",
    "print(\"Vector store cleared.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: Embedding model initialization and batching.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Embeddings shape (n_chunks, dim) printed.\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "mock_files = [\n",
    "    {\n",
    "        \"name\": \"test_paris.txt\",\n",
    "        \"type\": \"text/plain\",\n",
    "        \"data\": b\"The capital of France is Paris. Paris is known for the Eiffel Tower, \"\n",
    "                b\"the Louvre Museum, and its beautiful cafes. It is a major center for \"\n",
    "                b\"art and culture.\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"test_berlin.txt\",\n",
    "        \"type\": \"text/plain\",\n",
    "        \"data\": b\"Berlin is the capital of Germany. It is famous for the Brandenburg Gate \"\n",
    "                b\"and the remains of the Berlin Wall. It has a vibrant nightlife and tech scene.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "processor = DocumentProcessor()\n",
    "docs = processor.process_uploaded_files(mock_files)\n",
    "rag.add_documents(docs)\n",
    "print(f\"DocumentProcessor created {len(docs)} chunks from {len(mock_files)} files.\\n\")\n",
    "\n",
    "stats = rag.get_vector_store_stats()\n",
    "print(\"--- Vector-store stats after document ingestion ---\")\n",
    "pjson(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49484e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Vector Store Operations\n",
    "\n",
    "**Purpose:** Write/read embeddings to/from Vector DB (Chroma or FAISS). Expected: successful writes and accurate retrievals.\n",
    "\n",
    "**How to validate:** See the expected outputs in the code cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92fe5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: Vector store write and read checks.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Write confirmation and a top-k retrieval result.\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "crawler = WebCrawler()\n",
    "seed_urls = [\"https://en.wikipedia.org/wiki/Bread\"]\n",
    "crawled = crawler.crawl_root_urls(\n",
    "    seed_urls,\n",
    "    context=\"baking, history, flour\",\n",
    "    max_depth=1,\n",
    "    max_pages_per_url=2,   # <-- added\n",
    ")\n",
    "\n",
    "print(f\"\\nWebCrawler found {len(crawled)} relevant pages.\")\n",
    "if crawled:\n",
    "    rag.add_documents(crawled)\n",
    "    stats = rag.get_vector_store_stats()\n",
    "    print(\"--- Vector-store stats after web crawl ---\")\n",
    "    pjson(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25d5a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. RAG Engine Evaluation\n",
    "\n",
    "**Purpose:** Run retrieval + generation pipeline to answer queries. Expected: grounded and relevant answers.\n",
    "\n",
    "**How to validate:** See the expected outputs in the code cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c7d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: RAG engine run: retrieval + generation sample query.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Generated answer with retrieved context printed.\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "query = \"What is the capital of France?\"\n",
    "retrieved = rag.retrieve_relevant_documents(query, k=3)\n",
    "print(f\"\\nRetrieval test for: '{query}'\")\n",
    "pjson(retrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b07b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: RAG engine run: retrieval + generation sample query.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Generated answer with retrieved context printed.\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\n=== Generation tests ===\")\n",
    "\n",
    "q1 = \"What is Paris known for?\"\n",
    "print(f\"\\nQ: {q1}\")\n",
    "pjson(rag.generate_response(q1))\n",
    "\n",
    "q2 = \"What is bread?\"\n",
    "print(f\"\\nQ: {q2}\")\n",
    "pjson(rag.generate_response(q2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f3e231",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Knowledge Graph Tests\n",
    "\n",
    "**Purpose:** Extract entities and relationships and build graph. Expected: nodes/edges summary.\n",
    "\n",
    "**How to validate:** See the expected outputs in the code cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: Knowledge graph extraction from documents.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Node and edge counts printed; small sample graph.\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\n=== Multi-turn chat ===\")\n",
    "history = []\n",
    "\n",
    "turns = [\n",
    "    \"What is the capital of Germany?\",\n",
    "    \"How many people live there?\",\n",
    "    \"What is the Eiffel Tower?\",\n",
    "]\n",
    "\n",
    "for turn in turns:\n",
    "    print(f\"\\nHuman   : {turn}\")\n",
    "    reply = rag.chat_mode(turn, history)\n",
    "    print(f\"Assistant: {reply['answer']}\")\n",
    "    history.append({\"human\": turn, \"assistant\": reply[\"answer\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fdff73",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. LLM Response Validation\n",
    "\n",
    "**Purpose:** Check response quality, grounding and simple factual checks. Expected: metrics or pass/fail indicators.\n",
    "\n",
    "**How to validate:** See the expected outputs in the code cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: LLM response validation utilities.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Basic factuality check metrics (scores).\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\n=== Knowledge Graph ===\")\n",
    "kg_builder = KnowledgeGraphBuilder()\n",
    "\n",
    "all_docs = rag.get_all_documents_for_kg()\n",
    "print(f\"Building KG from {len(all_docs)} chunks…\")\n",
    "\n",
    "kg_stats = kg_builder.extract_entities_and_relationships(all_docs)\n",
    "print(\"\\n--- KG stats ---\")\n",
    "pjson(kg_stats)\n",
    "\n",
    "if kg_stats.get(\"graph_nodes\", 0):\n",
    "    fig = kg_builder.visualize_graph_plotly()\n",
    "    # Save interactive plot instead of trying to display in terminal\n",
    "    out_file = Path(\"knowledge_graph.html\")\n",
    "    fig.write_html(out_file)\n",
    "    print(f\"Interactive graph saved → {out_file.resolve()}\")\n",
    "else:\n",
    "    print(\"No nodes found for KG visualisation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db2c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: LLM response validation utilities.\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Basic factuality check metrics (scores).\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\nTest complete. \"\n",
    "      \"Delete 'chroma_db_store' and 'logs' folders if you want a fresh start next run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77edf0ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Streamlit UI Integration\n",
    "\n",
    "**Purpose:** Smoke test critical UI pages (upload, chat, graph). Expected: UI initialization and basic endpoints responding.\n",
    "\n",
    "**How to validate:** See the expected outputs in the code cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7e584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Purpose: Streamlit app smoke-start (no UI rendering in notebook).\n",
    "# Inputs: As defined by environment and previous cells\n",
    "# Expected Output: Confirmation message that Streamlit started or config is valid.\n",
    "# Validation: Verify printed output or returned objects match expectations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Read token from environment\n",
    "# ------------------------------------------------------------------\n",
    "api_key = os.getenv(\"HF_API_TOKEN\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"Export HF_TOKEN=<your-hugging-face-token> first\")\n",
    "\n",
    "\n",
    "s= \"explain yourself\"\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Build client\n",
    "# ------------------------------------------------------------------\n",
    "client = InferenceClient(\n",
    "    provider=\"featherless-ai\",\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Fire request\n",
    "# ------------------------------------------------------------------\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"inclusionAI/Ling-1T\",\n",
    "    messages=[{\"role\": \"user\", \"content\": s}],\n",
    "    max_tokens=250,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Display answer\n",
    "# ------------------------------------------------------------------\n",
    "answer = completion.choices[0].message.content\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
